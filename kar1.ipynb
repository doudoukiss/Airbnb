{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYdmx5E5j6/OdnAsLkQb7o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doudoukiss/Airbnb/blob/main/kar1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44WCED6tn75J"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "#words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#en(words)"
      ],
      "metadata": {
        "id": "Oonqxr2arCLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#min(len(w) for w in words)"
      ],
      "metadata": {
        "id": "ziG1hdADrXQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max(len(w) for w in words)"
      ],
      "metadata": {
        "id": "s55U0hYDrXYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = {}\n",
        "for w in words:\n",
        "  chs = ['<S>'] + list(w) + ['<E>']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    bigram = (ch1, ch2)\n",
        "    b[bigram] = b.get(bigram, 0) + 1"
      ],
      "metadata": {
        "id": "PnMuPwVNrXiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sorted(b.items(), key = lambda kv: -kv[1])[:10]"
      ],
      "metadata": {
        "id": "-1EgmMnUrXk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "mnTCYXM_zI_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27, 27), dtype = torch.int32)"
      ],
      "metadata": {
        "id": "bSh1Z5OXzI8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "#stoi['<S>'] = 26\n",
        "#stoi['<E>'] = 27\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s, i in stoi.items()}"
      ],
      "metadata": {
        "id": "7qQzFznyzI48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1, ix2] += 1"
      ],
      "metadata": {
        "id": "gEVQhNanzI2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.figure(figsize = (16,16))\n",
        "# plt.imshow(N, cmap='Blues')\n",
        "# for i in range(27):\n",
        "#   for j in range(27):\n",
        "#     chstr = itos[i] + itos[j]\n",
        "#     plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "#     plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "# plt.axis('off')"
      ],
      "metadata": {
        "id": "nFXKOKNnzIzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# p = N[0,:].float()\n",
        "# p = p / p.sum()\n",
        "P = (N+1).float()\n",
        "P /= P.sum(1, keepdim = True)"
      ],
      "metadata": {
        "id": "8sd1UQo1zIwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpoosRbyzOix",
        "outputId": "d7b6d1e8-f75b-4a27-9509-b1839152ed16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(202220222022)\n",
        "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "itos[ix]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gdA1LoWpzItR",
        "outputId": "94478e15-529c-4f71-de8d-061d359586e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(202220222022)\n",
        "\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    #p = N[ix].float()\n",
        "    #p = p / p.sum()\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement= True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    #print(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3PY-USuzIqX",
        "outputId": "7ef1bd68-3403-4940-9279-1cfa12d07c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ileyazevalyleet.\n",
            "pedral.\n",
            "gemen.\n",
            "ahahenuawon.\n",
            "day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "#for w in [\"lilin\"]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1, ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print(f'{log_likelihood = }')\n",
        "nll = - log_likelihood\n",
        "print(f'{nll/n=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eywmayYXzIgR",
        "outputId": "f1b893fa-64dd-4732-e084-f582181c7a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_likelihood = tensor(-559951.5625)\n",
            "nll/n=tensor(2.4544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the training set of bigrams (x, y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n"
      ],
      "metadata": {
        "id": "4_TRMk3432jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.imshow(xenc)"
      ],
      "metadata": {
        "id": "vQ1TcktkD_mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "i0ZPtvQgEHkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for the next character\n",
        "loss = - probs[torch.arange(5), ys].log().mean()"
      ],
      "metadata": {
        "id": "6HXhtf-qoMFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCcGN9nhp8wk",
        "outputId": "c2e6fb08-70ba-4783-c4d4-d5a307a0b2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6891677379608154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward pass\n",
        "W.grad = None # set to zero the gradient\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "Sls0U615nJ8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.data += -0.1 * W.grad"
      ],
      "metadata": {
        "id": "kme9pFdEp_je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W.grad.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN0T0GgvpVfj",
        "outputId": "0d3c8c20-3cfa-49bb-a802-256a9d40631c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([27, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization"
      ],
      "metadata": {
        "id": "EaU8LwleqljB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dataset\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# initialize the 'network'\n",
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKhyzBJyqop7",
        "outputId": "0ed0c53e-01e6-4b50-c8c3-06543d6e958d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of examples:  228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n",
        "import torch.nn.functional as F\n",
        "for k in range(10):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for the next character\n",
        "  loss = - probs[torch.arange(num), ys].log().mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN3mz4YXrTgw",
        "outputId": "a213b883-acb9-4e74-b13c-ef5a369deaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4553630352020264\n",
            "2.4553613662719727\n",
            "2.455359935760498\n",
            "2.4553580284118652\n",
            "2.4553563594818115\n",
            "2.455355405807495\n",
            "2.4553537368774414\n",
            "2.4553520679473877\n",
            "2.455350637435913\n",
            "2.4553492069244385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJsaQW6Is1aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('------------')\n",
        "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i, y]\n",
        "  print('probability assigned by the net to the next correct chracter:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood', logp.item())\n",
        "  nll = -logp\n",
        "  print('negative log likelihood:', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wZmi5Wvfsgr",
        "outputId": "17a43adc-7312-44c7-82e6-ab7e71925135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------\n",
            "bigram example 1: .e (indexes 0,5)\n",
            "input to the neural net: 0\n",
            "label (actual next character): 5\n",
            "probability assigned by the net to the next correct chracter: 0.01228625513613224\n",
            "log likelihood -4.399273872375488\n",
            "negative log likelihood: 4.399273872375488\n",
            "------------\n",
            "bigram example 2: em (indexes 5,13)\n",
            "input to the neural net: 5\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the next correct chracter: 0.018050700426101685\n",
            "log likelihood -4.014570713043213\n",
            "negative log likelihood: 4.014570713043213\n",
            "------------\n",
            "bigram example 3: mm (indexes 13,13)\n",
            "input to the neural net: 13\n",
            "label (actual next character): 13\n",
            "probability assigned by the net to the next correct chracter: 0.026691533625125885\n",
            "log likelihood -3.623408794403076\n",
            "negative log likelihood: 3.623408794403076\n",
            "------------\n",
            "bigram example 4: ma (indexes 13,1)\n",
            "input to the neural net: 13\n",
            "label (actual next character): 1\n",
            "probability assigned by the net to the next correct chracter: 0.07367686182260513\n",
            "log likelihood -2.6080665588378906\n",
            "negative log likelihood: 2.6080665588378906\n",
            "------------\n",
            "bigram example 5: a. (indexes 1,0)\n",
            "input to the neural net: 1\n",
            "label (actual next character): 0\n",
            "probability assigned by the net to the next correct chracter: 0.014977526850998402\n",
            "log likelihood -4.201204299926758\n",
            "negative log likelihood: 4.201204299926758\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnEvB07nfyGg",
        "outputId": "4fbf6c75-1231-46e9-bc78-a794ddcacace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnR5MGMBpAZg",
        "outputId": "5bab020e-fa9a-445f-c65e-5b7d8f6f5481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.7693, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    }
  ]
}